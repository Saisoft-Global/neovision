{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDP Backend Server\n",
    "\n",
    "Run this notebook to start the FastAPI backend server with ngrok tunnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install fastapi uvicorn[standard] python-multipart torch transformers Pillow paddleocr python-magic-bin spacy pyngrok python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download spaCy model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "from PIL import Image\n",
    "import io\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Configure CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Load models\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "@app.post(\"/process-document\")\n",
    "async def process_document(file: UploadFile):\n",
    "    try:\n",
    "        contents = await file.read()\n",
    "        image = Image.open(io.BytesIO(contents))\n",
    "        \n",
    "        # Process image with LayoutLMv3\n",
    "        encoding = processor(image, return_tensors=\"pt\")\n",
    "        outputs = model(**encoding)\n",
    "        \n",
    "        # Extract text with spaCy\n",
    "        doc = nlp(text)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"entities\": entities\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\"status\": \"healthy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ngrok tunnel\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "NGROK_TOKEN = \"YOUR_NGROK_TOKEN\"  # Replace with your token\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(8000)\n",
    "print(f\"\\nBackend URL: {public_url}\")\n",
    "print(\"\\nUpdate your frontend .env file with:\")\n",
    "print(f\"VITE_API_URL={public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the FastAPI server\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}