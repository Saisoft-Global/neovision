{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "IDP Backend Server",
   "private_outputs": true,
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# IDP Backend Server\n",
    "\n",
    "This notebook runs the FastAPI backend server with ngrok tunnel for document processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install_deps"
   },
   "source": [
    "# Install required packages\n",
    "!pip install -q fastapi==0.110.0 \\\n",
    "    uvicorn[standard]==0.27.1 \\\n",
    "    python-multipart==0.0.9 \\\n",
    "    torch torchvision --index-url https://download.pytorch.org/whl/cpu \\\n",
    "    transformers==4.38.2 \\\n",
    "    Pillow==10.2.0 \\\n",
    "    paddleocr==2.7.0.3 \\\n",
    "    python-magic==0.4.27 \\\n",
    "    spacy==3.7.4 \\\n",
    "    pyngrok==7.1.5 \\\n",
    "    python-dotenv==1.0.1 \\\n",
    "    nest-asyncio==1.6.0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "download_spacy"
   },
   "source": [
    "# Download spaCy model\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "create_dirs"
   },
   "source": [
    "# Create necessary directories\n",
    "!mkdir -p models/layout models/spacy data/annotations"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "write_app"
   },
   "source": [
    "%%writefile app.py\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from typing import Dict, Any, List, Optional\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import spacy\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "import re\n",
    "import magic\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize models\n",
    "        self.ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=torch.cuda.is_available(), show_log=False)\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        \n",
    "        # Initialize LayoutLMv3\n",
    "        layout_model_name = \"microsoft/layoutlmv3-base\"\n",
    "        self.layout_processor = LayoutLMv3Processor.from_pretrained(layout_model_name)\n",
    "        self.layout_model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "            layout_model_name,\n",
    "            num_labels=len(self.label2id)\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Label mappings\n",
    "        self.label2id = {\n",
    "            \"O\": 0,\n",
    "            \"B-invoice_number\": 1,\n",
    "            \"B-date\": 2,\n",
    "            \"B-total_amount\": 3,\n",
    "            \"B-tax_amount\": 4,\n",
    "            \"B-vendor_name\": 5,\n",
    "            \"B-customer_name\": 6,\n",
    "            \"B-line_item\": 7,\n",
    "            \"B-quantity\": 8,\n",
    "            \"B-unit_price\": 9,\n",
    "            \"B-description\": 10\n",
    "        }\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "\n",
    "    def process_image(self, image: Image.Image) -> Dict[str, Any]:\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Extract text with OCR\n",
    "        ocr_result = self.ocr.ocr(img_array)\n",
    "        text_blocks = self._extract_text_blocks(ocr_result)\n",
    "        \n",
    "        # Process with LayoutLMv3\n",
    "        layout_fields = self._process_with_layout(image, text_blocks)\n",
    "        \n",
    "        # Enhance with NER\n",
    "        enhanced_fields = self._enhance_with_spacy(layout_fields)\n",
    "        \n",
    "        # Apply pattern matching\n",
    "        final_fields = self._apply_pattern_matching(enhanced_fields)\n",
    "        \n",
    "        # Classify document\n",
    "        doc_type = self._classify_document_type(final_fields)\n",
    "        \n",
    "        return {\n",
    "            \"fields\": final_fields,\n",
    "            \"documentType\": doc_type,\n",
    "            \"confidence\": self._calculate_confidence(final_fields)\n",
    "        }\n",
    "\n",
    "    def _extract_text_blocks(self, ocr_result):\n",
    "        text_blocks = []\n",
    "        for block in ocr_result:\n",
    "            for line in block:\n",
    "                bbox = line[0]\n",
    "                text = line[1][0]\n",
    "                confidence = line[1][1]\n",
    "                \n",
    "                text_blocks.append({\n",
    "                    \"text\": text,\n",
    "                    \"bbox\": [\n",
    "                        min(p[0] for p in bbox),\n",
    "                        min(p[1] for p in bbox),\n",
    "                        max(p[0] for p in bbox),\n",
    "                        max(p[1] for p in bbox)\n",
    "                    ],\n",
    "                    \"confidence\": confidence\n",
    "                })\n",
    "        return text_blocks\n",
    "\n",
    "    def _process_with_layout(self, image, text_blocks):\n",
    "        encoding = self.layout_processor(\n",
    "            image,\n",
    "            text=[block[\"text\"] for block in text_blocks],\n",
    "            boxes=[block[\"bbox\"] for block in text_blocks],\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.layout_model(**encoding)\n",
    "            predictions = outputs.logits.argmax(-1).squeeze().cpu().numpy()\n",
    "        \n",
    "        fields = []\n",
    "        for idx, (pred, block) in enumerate(zip(predictions, text_blocks)):\n",
    "            label = self.id2label[pred]\n",
    "            if label != \"O\":\n",
    "                field_type = label[2:]\n",
    "                fields.append({\n",
    "                    \"id\": f\"{field_type}_{len(fields)}\",\n",
    "                    \"label\": field_type.replace(\"_\", \" \").title(),\n",
    "                    \"value\": block[\"text\"],\n",
    "                    \"confidence\": float(outputs.logits.softmax(-1)[0, idx, pred].cpu().numpy()),\n",
    "                    \"bbox\": block[\"bbox\"]\n",
    "                })\n",
    "        \n",
    "        return fields\n",
    "\n",
    "    def _enhance_with_spacy(self, fields):\n",
    "        enhanced_fields = []\n",
    "        for field in fields:\n",
    "            doc = self.nlp(field[\"value\"])\n",
    "            entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "            if entities:\n",
    "                field[\"confidence\"] = min(1.0, field[\"confidence\"] + 0.1)\n",
    "                field[\"entities\"] = entities\n",
    "            enhanced_fields.append(field)\n",
    "        return enhanced_fields\n",
    "\n",
    "    def _apply_pattern_matching(self, fields):\n",
    "        patterns = {\n",
    "            'invoice_number': r'(?i)inv[oice]*[\\s#:]+([A-Z0-9-]+)',\n",
    "            'date': r'(?i)(?:date[d:\\s]*)?(\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4})',\n",
    "            'amount': r'\\$?\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)',\n",
    "            'email': r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+',\n",
    "            'phone': r'(?:\\+\\d{1,3}[-\\.\\s]?)?\\(?\\d{3}\\)?[-\\.\\s]?\\d{3}[-\\.\\s]?\\d{4}'\n",
    "        }\n",
    "        \n",
    "        for field in fields:\n",
    "            for pattern_type, pattern in patterns.items():\n",
    "                if re.search(pattern, field[\"value\"]):\n",
    "                    field[\"pattern_match\"] = pattern_type\n",
    "                    field[\"confidence\"] = min(1.0, field[\"confidence\"] + 0.05)\n",
    "        \n",
    "        return fields\n",
    "\n",
    "    def _classify_document_type(self, fields):\n",
    "        text = \" \".join(f\"{field['label']} {field['value']}\" for field in fields).lower()\n",
    "        \n",
    "        if any(word in text for word in [\"invoice\", \"bill to\"]):\n",
    "            return \"invoice\"\n",
    "        elif any(word in text for word in [\"purchase order\", \"po number\"]):\n",
    "            return \"purchase_order\"\n",
    "        elif any(word in text for word in [\"receipt\", \"merchant\"]):\n",
    "            return \"receipt\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "\n",
    "    def _calculate_confidence(self, fields):\n",
    "        if not fields:\n",
    "            return 0.0\n",
    "        return sum(field[\"confidence\"] for field in fields) / len(fields)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "doc_processor = DocumentProcessor()\n",
    "\n",
    "ALLOWED_MIME_TYPES = ['image/jpeg', 'image/png', 'image/tiff', 'application/pdf']\n",
    "\n",
    "@app.post(\"/process-document\")\n",
    "async def process_document(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        content = await file.read()\n",
    "        mime = magic.Magic(mime=True)\n",
    "        file_type = mime.from_buffer(content)\n",
    "        \n",
    "        if file_type not in ALLOWED_MIME_TYPES:\n",
    "            raise HTTPException(status_code=400, detail=f\"Unsupported file type: {file_type}\")\n",
    "        \n",
    "        image = Image.open(io.BytesIO(content))\n",
    "        result = doc_processor.process_image(image)\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\"status\": \"healthy\"}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "setup_ngrok"
   },
   "source": [
    "# Setup ngrok tunnel\n",
    "from google.colab import userdata\n",
    "NGROK_TOKEN = userdata.get('NGROK_TOKEN')  # Set this in Colab secrets\n",
    "\n",
    "if not NGROK_TOKEN:\n",
    "    print(\"Please set your ngrok auth token in Colab secrets!\")\n",
    "    print(\"1. Go to https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"2. Copy your auth token\")\n",
    "    print(\"3. In Colab: Runtime -> Secrets -> Add new secret\")\n",
    "    print(\"4. Name: NGROK_TOKEN, Value: your_token\")\n",
    "    raise ValueError(\"Ngrok token not found\")\n",
    "\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "\n",
    "public_url = ngrok.connect(8000)\n",
    "print(f\"\\nBackend URL: {public_url}\")\n",
    "print(\"\\nUpdate your frontend .env file with:\")\n",
    "print(f\"VITE_API_URL={public_url}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "start_server"
   },
   "source": [
    "# Start the FastAPI server\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}